{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detrended Fluctuation Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detrended fluctuation analysis (DFA) is used to uncover the degree of self-similarity within a time series. In brief, it estimates the self-similarity within a time series by calculating the average magnitude of variance across a range of window sizes (e.g., 8, 16, 32 etc. samples), and then plots these variance magnitude measures as a function of window size on a log-log plot. The slope of best fit, ùõº, can then be used as an estimate of self-similarity. DFA is specifically designed to analyze monofractal signals, including fractional Gaussian noise (fGn; a stationary series of fluctuations) and fractional Brownian motion (fBm; a non-stationary series of fluctuations). \n",
    "\n",
    "#### Interpreting Alpha (ùõº)\n",
    "DFA returns alpha as an index of self-similarity. Here, ùõº ‚âà 0.5 indicates random, uncorrelated variation (‚Äúwhite noise‚Äù), ùõº ‚âà 1.0 indicates fractal, power law scaling (‚Äúpink noise‚Äù), and ùõº ‚âà 1.5 indicates highly persistent and correlated patterns of Brownian motion (‚Äúbrown noise‚Äù).\n",
    "\n",
    "#### Let's Practice Running DFA\n",
    "Before we begin, we need to import and load various packages and utilities. These will allow us to import the data, manipulate it, run DFA, and create visualisations to explore our results.\n",
    "\n",
    "The code below will do all the setup for you. Simply click the \"play\" button on the left to run the code, and we'll be ready to start our analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from utils import filter_data, interpolate_missing_data\n",
    "from utils.dfa_utils import perform_dfa_for_plotting\n",
    "from utils.plot_utils import plot_ts_and_dfa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that all the utilities are loaded, it's time to apply DFA to some real data ‚Äî in this case, [postural sway data](data/dfa/postureA.txt).\n",
    "\n",
    "Just click the \"play\" button below to perform the analysis and generate the visualisations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First set the directory path for the data\n",
    "data_directory = \"data/dfa/\"\n",
    "\n",
    "# Then decide whether you'd like to save the plots \n",
    "# These are saved in \"images/dfa\"\n",
    "save_image = True\n",
    "\n",
    "# Set the file name for the data\n",
    "file_name = \"postureA.txt\"\n",
    "file_path = os.path.join(data_directory, file_name)\n",
    "\n",
    "# Check whether the file containing the data exists\n",
    "if os.path.exists(file_path):\n",
    "    print(f'Loading file: {file_name}')\n",
    "\n",
    "    # Load the CSV file into a DataFrame\n",
    "    data = pd.read_csv(file_path, header=None, sep='\\t')\n",
    "\n",
    "    # Interpolate any missing data that might be present in the file\n",
    "    data = interpolate_missing_data(data)\n",
    "\n",
    "    # Apply a filter to the data\n",
    "    data = filter_data(data)\n",
    "    \n",
    "    # Normalise the data by using a z-score\n",
    "    data = (data - data.mean()) / data.std()\n",
    "\n",
    "    # Perform DFA analysis using the perform_dfa_for_plotting function from dfa_utils\n",
    "    dfa_results = perform_dfa_for_plotting(data)\n",
    "\n",
    "    # Plot time series and DFA results side-by-side\n",
    "    for column, results in dfa_results.items():\n",
    "        print(f'Alpha value for column {column}: {results[\"alpha\"]}')\n",
    "        alpha = results['alpha']\n",
    "        scales = results['scales']\n",
    "        flucts = results['flucts']\n",
    "        fit_line = results['fit_line']\n",
    "\n",
    "        # Plotting code (assuming a plot function is available)\n",
    "        plot_filename = f'images/dfa/{file_name}_dfa_{column}_plot.png'\n",
    "        plot_ts_and_dfa(data[column].values, scales, flucts, fit_line, alpha, save_image, plot_filename)\n",
    "\n",
    "    print('DFA analysis and plotting completed successfully!')\n",
    "else:\n",
    "    print(f'File {file_name} not found in directory {data_directory}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpreting the Results\n",
    "\n",
    "If your code ran successfully, you should see an alpha value of 1.05. This indicates fractal, power law scaling (‚Äúpink noise‚Äù).\n",
    "\n",
    "Now let's see how this metrics compare to a different person's postural sway. Click \"play\" on the code chunk before to run DFA on another signal, and observe the differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First set the directory path for the data\n",
    "data_directory = \"data/dfa/\"\n",
    "\n",
    "# Then decide whether you'd like to save the plots \n",
    "# These are saved in \"images/rqa\"\n",
    "save_image = True\n",
    "\n",
    "# Set the file names for the data\n",
    "file_names = [\"postureA.txt\", \"postureB.txt\"]\n",
    "\n",
    "# Loop through each file for analysis\n",
    "for file_name in file_names:\n",
    "    file_path = os.path.join(data_directory, file_name)\n",
    "\n",
    "    # Check whether the file containing the data exists\n",
    "    if os.path.exists(file_path):\n",
    "        print(f'Loading file: {file_name}')\n",
    "\n",
    "        # Load the CSV file into a DataFrame\n",
    "        data = pd.read_csv(file_path, header=None, sep='\\t')\n",
    "\n",
    "        # Interpolate any missing data that might be present in the file\n",
    "        data = interpolate_missing_data(data)\n",
    "\n",
    "        # Apply a filter to the data\n",
    "        data = filter_data(data)\n",
    "        \n",
    "        # Normalise the data by using a z-score\n",
    "        data = (data - data.mean()) / data.std()\n",
    "\n",
    "        # Perform DFA analysis using the perform_dfa_for_plotting function from dfa_utils\n",
    "        dfa_results = perform_dfa_for_plotting(data)\n",
    "\n",
    "        # Plot time series and DFA results side-by-side\n",
    "        for column, results in dfa_results.items():\n",
    "            print(f'Alpha value for column {column}: {results[\"alpha\"]}')\n",
    "            alpha = results['alpha']\n",
    "            scales = results['scales']\n",
    "            flucts = results['flucts']\n",
    "            fit_line = results['fit_line']\n",
    "\n",
    "            # Plotting code (assuming a plot function is available)\n",
    "            plot_filename = f'images/dfa/{file_name}_dfa_{column}_plot.png'\n",
    "            plot_ts_and_dfa(data[column].values, scales, flucts, fit_line, alpha, save_image, plot_filename)\n",
    "\n",
    "        print('DFA analysis and plotting completed successfully!')\n",
    "    else:\n",
    "        print(f'File {file_name} not found in directory {data_directory}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparing the Results\n",
    "\n",
    "If you examine the plots and the resulting alpha, you'll notice that the second participant's postural sway is less persistent than the first (i.e., closer to white noise)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Going Further\n",
    "\n",
    "To expand your understanding of DFA, you can try the following:\n",
    "\n",
    "1. Analyse other time series: Repeat the analyses above with other types of continuous data such as [walking](data/dfa/Gait1.txt).\n",
    "2. Run a windowed DFA: To assess how patterns of behavioural variability change over time, explore [Windowed DFA](dfaWindowed.ipynb) which walks you through performing windowed DFA.\n",
    "3. Explore complexity matching: Fractal scaling in human behavioural time series has been shown to algin with an interaction partner. Explore different ways to quantify [Complexity Matching](complexitymatching.ipynb)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "matb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
